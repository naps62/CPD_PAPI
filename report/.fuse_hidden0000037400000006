\documentclass[a4paper,10pt]{report}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{ucs}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage{indentfirst}

\usepackage{amsmath}
\usepackage[retainorgcmds]{IEEEtrantools}%	IEEEeqnarray

\usepackage{multi row}%	row span in tables

\usepackage{varioref}%	context sensitive references (prints page when far away)
\usepackage{hyperref}%	hyperlinks, references with automatic descriptions
\usepackage{hypcap}
\usepackage{titlesec}

\usepackage{listings}
\lstset{
	language=c,
	basicstyle=\footnotesize,
	showtabs=true,
	tabsize=3,
	showtabs=false,
}

\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

\renewcommand*\thesection{\arabic{section}}

\begin{document}

\tableofcontents

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION 1: ROOFLINE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Roofline}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBECTION 1.1: Profiling
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Profiling}
The computer characterized here is the HP dv5-1170ep, released in 2008.

Most of the hardware was obtained from the Intel ARK Website \cite{ark} and from standard Linux tools:
\begin{description}
\item[dmidecode] Tool for hardware dump from BIOS information;
\item[lscpu] Lists CPU information;
\item[lshw] Lists hardware information
\item[getconf] Lists various configuration variables (e.g. cache organization values)
\end{description}

AIDA64 Extreme Edition for Windows 7 was used to measure memory latencies (\autoref{fig:aida64}). It's results were then compared against the previosly obtained data to ensure it's accuracy.
Some of the data is theorethically calculated based on the given hardware characteristics. This, of course, represents only a theorethical limit for the hardware, and not actually measured data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSUBSECTION 1.1.1: Peak FP Performance
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Peak Floating-Point Performance}
In order to keep coherency with the Roofline paper\cite{roofline}, Peak FP Performance was measured using double-precision floating point numbers. The formula to calculate the maximum double precision floating point throughput is:

$$\mathrm{Flop/s_{max}} = T_{\mathrm{FP}} \times f_{\mathrm{clock}} \times \#_{\mathrm{cores}}$$

Where $T_{\mathrm{FP}}$ is the double precision floating point throughput of each core.

The CPU in question, Core 2 Duo P8600, has two cores working with a clock rate of 2.4 GHz. Being based on the Core micro architecture, each core has one execution unit for 128-bit floating point addition, and one for multiplication. When considering SIMD operations, with the SSE and MMX extensions, then each 128-bit register can carry two double precision floating point values, thus effectively doubling the throughput. With an ideal multiply/add balance, four floating point operations can run in parallel.

\begin{IEEEeqnarray}{CrClC}
\Rightarrow		& \mathrm{Flop/s_{max}} & = & 4 \times \left (2.4 \times 10^9 \right ) \times 2 & \Leftrightarrow	\nonumber \\
\Leftrightarrow	& \mathrm{Flop/s_{max}} & = & 19.2\;\mathrm{GFlop/s} & \nonumber
\end{IEEEeqnarray}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSUBSECTION 1.1.2: Peak Mem BW
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Peak Memory Bandwidth}
This value can be calculated based on the memory clock rate and the memory bus. Multiple channels should also be taken into account.
The memory is a SDRAM DDR2 operating at a clock rate of 800MHz, and using two modules, taking advantage of the dual-channel. The bus width is 64 bits (or 8 Bytes)

\begin{IEEEeqnarray}{CrClC}
\Rightarrow		& \mathrm{BW_{max}} & = & MEM_{\mathrm{clock}} \times bus_{\mathrm{width}} \times \#\mathrm{channels} & \Leftrightarrow \\
\Leftrightarrow	& \mathrm{BW_{max}} & = & (800 \times 10^9) \times 64 \times 2 & \Leftrightarrow \nonumber \\
\Leftrightarrow & \mathrm{BW_{max}} & = & 12.8\;\mathrm{GB/s} & \nonumber
\end{IEEEeqnarray}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBsubSECTION 1.2.3: Summary
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Summary}
The full characterization of the laptop is summarized in \autoref{tab:profile}

\begin{table}[!htp]

\begin{minipage}[t]{0.5\linewidth}
	\vspace{0pt}
	%\begin{center}
		\begin{tabular}{|rl|}
			\multicolumn{2}{c}{\textbf{Laptop}}				\\
			\hline
				Manufacturer		&	HP					\\
				Model				&	Pavilion dv5 1170ep	\\
			\hline
			\multicolumn{2}{c}{} 							\\
			\multicolumn{2}{c}{\textbf{Processor}} 			\\
			\hline
				Manufacturer:		&	Intel				\\
				Model:				&	P8600				\\
				$\mu$-arch			&	Core				\\
				Codename			&	Penryn-3M			\\
				Clock frequency		&	2.4 GHz				\\
				Cores				&	2					\\
				Threads:			&	2					\\
				Peak Flop/s			&	19.2 GFlop/s		\\
			\hline
		\end{tabular}
	%%\end{center}

\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
	\vspace{0pt}
	%\begin{center}

		\begin{tabular}{|c|rl|}
			\multicolumn{3}{c}{\textbf{Memory}}		\\
			\hline
			\multicolumn{1}{|c|}{\multirow{5}{*}{L1}}
				&	Scope			&	Core		\\
				&	Size			&	32KB + 32KB	\\
				&	Associativity	&	8-way		\\
				&	Line Size		&	64 B		\\
				&	Write Policy	&	Write-back	\\
			\hline
			\multicolumn{1}{|c|}{\multirow{5}{*}{L2}}
				&	Scope			&	shared		\\
				&	Size			&	3MB			\\
				&	Associativity	&	12-way		\\
				&	Line Size		&	64 B		\\
				&	Write Policy	&	Write-back	\\
			\hline

			%\textbf{Main Memory:}	&				&		\\
			\multicolumn{1}{|c|}{\multirow{6}{*}{RAM}}
				&	Type			&	SDRAM DDR2 PC6400	\\
				&	Frequency		&	800 MHz				\\
				&	Num. Channels	&	2					\\
				&	Size			&	4 GB				\\
				&	Latency			&	81.1 ns				\\
				&	Peak Bandwith	&	12.8 GB/s			\\
			\hline			
		\end{tabular}
	%\end{center}
\end{minipage}
	\caption{Laptop characterization \label{tab:profile}}
\end{table}
~

\begin{figure}[!htp]
	\begin{center}
		\includegraphics[width=12cm]{images/aida64.png}
		\caption[Memory benchmark]{Memory benchmark with Aida64 Extreme Edition \label{fig:aida64}}
	\end{center}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\include{sec1roofline}
% SSUBSECTION 1.3. ROOFLINE MODEL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Roofline}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUSUBSBECTION 1.3.1. ROOFS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Roofs}

Based on the data gathered from the laptop characterization, and the information from the Roofline paper \cite{roofline}, both roofs for the model can be easily calculated by the formula:

$$ Flops/sec = min(Peak Flops/sec, Memory Bandwidth \times Op. Intensity ) $$

The first part of the $\mathrm{min}$ function gives the CPU roof, which is equal to the CPU's peak Flop performance. The memory roof increases linearly with the Operational Intensity (as the operational intensity increases, problems become more CPU-bound and less memory-bound)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSUBSECTION 1.3.2. CEILINGS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Ceilings}

Ceilings were added to the model by gradually recalculating the roofs without a certain architecture characteristic. Each ceiling is given by the value of the previous ceiling (with the roof being the base value), divided by a factor which represents the weight that the removed characteristic had in the performance. The ceilings estimated were:
\begin{description}
	\item[All cores used]This corresponds to the roof, where all the resources are considered.
	\item[Mul/Add balance, No TLP (only one core)]This ceiling considers only the usage of a single core, against two cores in the previous. This represents a reduction in peak performance by a factor of 2, so the ceiling has half the value of the previous one.
	\item[With SIMD (no Mul/Add balance)]Here, it was considered that multiplication and addition instructions were not balanced. Without this balance, the hardware won't be used to it's full potential. Each core has two SSE units, one unit to process multiplications and another for additions. It also has two normal units, but they can't be used at the same time. So if only one of those is busy at each instant, the performance is again halved.
	\item[ILP Only (no SIMD)]Finally SIMD were removed. Since everything was measured using double-precision floating point numbers, SIMD would allow two FP operations to be processed each clock cycle. Without SIMD, only one will be processed, which is half of the original performance
\end{description}

For the memory, only one ceiling was estimated. This ceiling occurs when dual channel is removed, which theoretically drops memory bandwith to half its value.

\autoref{tab:ceilings} shows a summary of all the ceilings calculated, and it's value

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TABLE 
\begin{table}[!htp]
	\begin{center}
		\begin{tabular}{|c|c|c|}
				\hline
				&	\textbf{Ceiling}	&	\textbf{Value (GFlops)}	\\
				\hline
				\hline
			\multicolumn{1}{|c|}{\multirow{4}{*}{CPU}}
				&	All cores used		&	19.2					\\
				&	Mul/Add balance		&	9.6						\\
				&	With SIMD			&	4.8						\\
				&	ILP Only			&	2.4						\\
			\hline
			\hline
			\multicolumn{1}{|c|}{\multirow{2}{*}{Memory}}
				&	All channels used	&	12.8\footnotemark		\\
				&	No dual channel		&	6.4						\\
				\hline
		\end{tabular}
	\end{center}
	\caption{Ceiling values for Roofline Mode \label{tab:ceilings}}
\end{table}
\footnotetext{This value correspondes to an operational intensity of 1}

\autoref{fig:roofline} shows the graph for the Roofline model. \autoref{fig:rooflinex4} shows the same Roofline model overlaped with the Roofline for the Opteron X4, for comparison.

\newpage

\begin{figure}[!htp]
	\begin{minipage}[t]{0.5\linewidth}
		\includegraphics[width=\textwidth]{images/roofline.eps}
		\caption[Roofline Model]{Roofline Model based on laptop characterization \label{fig:roofline}}
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}[t]{0.5\linewidth}
		\includegraphics[width=\textwidth]{images/x4roofline.eps}
		\caption[Roofline Model with Opteron X4]{Roofline Model based, overlaped with Roofline Model for the Opteron X4 \label{fig:rooflinex4}}
	\end{minipage}
\end{figure}

The main difference between the P8600 that was used and the Opteron X4 is in the number of cores. Both processors have two SSE units, and two regular units (sharing the issue port with the SSE units) per core, with each SSE isntructions usign 128 bit registers in both processors. So each one can process 2 double precision floating points per cycle(assumind a fully pipelined architecture with a latency of one cycle per instruction). The clock frequency is roughly the same (2.4 GHz in the P8600, 2.3 GHz in the Opteron X4). The Opteron system showed here uses a dual-socket architecture, with two Opteron X4, for a total of 8 cores, four times more than the laptop architecture. This matches the expected values for the roofline model, which shows that the peak performance for the dual Opteron X4 system is around 4 times higher than the laptop.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION 2: ALGORITHM ANALYSIS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithm Analysis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 2.1: ALGORITHM
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The N-Body Algorithm}

In this report, it was required to analyse the performance of the \emph{N-Body} algorithm, which is used to simulate the interaction between a set of objects, and the interactions betweeen them. One example application of this algorithm is simulating the influence that the planet's gravitational force on the other planets in the set, and estimate it's position in the future.

The formula implemented for this analysis is the following:

\begin{IEEEeqnarray}{C}
	\begin{cases}
	{\forall}_{x \in N} \; p_{x}(t + {\Delta}t) = p_{x}(t) + v_{x}(t) + \frac{1}{2}{\Delta}t^{2}a_{x}(t) \nonumber \\
	\\
	\; a_{x}(t) = G \sum_{i=1}^{N} \frac{m_{i} | p_{x} - p{i} |}{| p_{x} - p_{i} |} \nonumber \\
	\end{cases}
\end{IEEEeqnarray}

The formula states that the position of an object $x$ after ${\Delta}t$ units of time, is given by the sum between its previous position, velocity and acceleration. The acceleration is computed iteratively, based on the mass and position of all the other objects in the set. In general, the naive version of this algorithm (the one tested here) runs on $\Theta(N^{2})$. There are much better implementations of this algorithm, down to a complexity of $O(N log(N))$, however they were not the object of study here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 2.1: PARTICULAR PROBLEM: SQUARE ROOT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Particular Problem: Square root}

The algorithm requires que calculation of a square root for every interaction, for a total of $N^{2}$ square root calculations for the whole algorithm. This C stantard implementation uses Newton's iterative method, which has an execution time that cannot be estimated easily. Since the focus here is on performance analysis rather that accurate results, it was decided that a different square root implementation should be used.

The selected implementation was taken from a small comparison of square root implementations (see \cite{sqrt}), and it was the one on the article that provided the nearest speed and accuracy compared to the standard implementation, and also had support for double precision floats (some of the implementations didn't because they assumed a 32-bit number and relied on bit shift operations).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 2.2: TEST CASES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Test Cases}

Six test cases were choosen, so that two cases could fit on each memory level. \autoref{tab:testcases} specifies their names and details. For a simulation with the algorithm, each object requires a total of 10 double precision floats: 3 for position vector, 3 for velocity, 1 for mass, and 3 for a temporary vector to hold the next position, which was required to keep the newly calculated position of the object, since the original position vector could only be updated after the entire iteration was over.

\begin{table}[!htp]
	\begin{center}
		\begin{tabular}{|l|l|l|}
			\hline
			\textbf{Test Name}	&	\textbf{Size (N)}	&	\textbf{Size}	\\
			\hline
			L1\_1				&	64					&	5 KB			\\
			L1\_2				&	128					&	10 KB			\\
			L2\_1				&	8192				&	0.625 MB		\\
			L2\_2				&	16384				&	1.25 MB			\\
			RAM\_1				&	65536				&	5 MB			\\
			RAM\_2				&	131072				&	10 MB			\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Test cases used in the analysis \label{tab:testcases}}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 2.2: TEST METHODOLOGY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Test Methodology}

To measure the implementation's performance, Performance API (PAPI) was used. This tool provides a set of counters, directly supported by the processor hardware, to enable low-level event measures. \autoref{tab:counters} lists all counters used in this report. Counters described as native are the ones fully supported by the hardware, while derived events are estimated based on other native events, so they may not be as much accurate. So in total, each object uses $10 \times 64 / 8 = 80$ Bytes.

\begin{table}[!htp]
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{Counters}	&	\textbf{Description}		&	\textbf{Type}	\\
			\hline
			PAPI\_TOT\_CYC		&	Total cycles				&	Native			\\
			PAPI\_TOT\_INS		&	Total instructions			&	Native			\\
			PAPI\_LD\_INS		&	Load Instructions			&	Native			\\
			PAPI\_SR\_INS		&	Store Instructions			&	Native			\\
			PAPI\_FML\_INS		&	Multiply instructions		&	Native			\\
			PAPI\_FDV\_INS		&	Division instructions		&	Native			\\
			PAPI\_VEC\_INS		&	Vector Instructions			&	Native			\\
			PAPI\_FP\_OPS		&	Floating point operations	&	Native			\\
			PAPI\_L1\_DCA		&	L1 data cache accesses		&	Native			\\
			PAPI\_L1\_DCM		&	L1 data cache misses		&	Native			\\
			PAPI\_L2\_DCA		&	L2 data cache accesses		&	Derived			\\
			PAPI\_L2\_DCM		&	L2 data cache misses		&	Derived			\\
			\hline
		\end{tabular}
	\end{center}
	\caption{PAPI counters used \label{tab:counters}}
\end{table}

The algorithm was implemented in C, along with function calls to PAPI to manage hardware counters. The code was compiled with the level 3 optimization flag.

All counters were ran on a dedicated execution of the algorithm, to avoid conflicts between them. Also, to avoid possible problems with core affinity and thread scheduling, only one core was enabled on the laptop, and all major processes (graphical interface, network, etc) were disabled to minimize the overhead.

For each test case, all counters were measured at least three times, and it was guaranteed to have an execution time that had a difference not greater than 5\% between all three executions.

Prior to the execution, a file was generated with enough double precision floating point numbers to fill all the data structures of the biggest test case. This input file was used for all executions.

A bash script was made to handle all the test process. It is responsible for invoking the compiled C program the necessary number of times, each time measuring a different counter with a different test case, and saving the counter result. After the 3 runs necessary for each counter, the execution time was checked, and only the one with the lowest time was considered.

It should be noted that, while smaller tests were very fast to execute, bigger ones (especially the last two, that only fit on RAM), because of the fact that each test case required a total of 30 executions of the program, were too slow to consider increasing the test size, which could possibly provide a better understanding of the impact the different memory levels have on performance. For example, the RAM\_1 test only uses 5MB of memory, while the cache L2 of the laptop can hold 3MB. This small difference could mean that some of the data might get cached in the L2, thus not providing the expected results, since this test aimed to measure main memory traffic.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION 3: TEST RESULTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Test Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 3.1: MEMORY ACCESSES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Memory Accesses}

After running all test cases, one of the first measurements made was to attempt an estimation of the number of memory accesses (either cache or main memory), and then compare it agains the corresponding PAPI counters (PAPI\_LD\_INS and PAPI\_SR\_INS). By analysis of the C code itself this would not be possible, since the use of registers allows many of the implicit memory accesses to be optimized by the compiler. So it was necessary to analyse the Assembly code generated from the compiler.

After analysing the structure of the Assembly code, the main loops were identified. They followed the same flow from the C algorithm, which is shown in \autoref{lst:assembly}, along with the number of load/store instructions in each region

\begin{lstlisting}[label=lst:assembly]
	for(1 to N) {
		[4 stores, 1 load, 7 instr.]
		for(1 to N) {
			[6 stores, 3 loads, 34 instr.]
		}
		[3 stores, 6 loads, 26 instr.]
	}
	for(1 to N) {
		[3 stores, 3 loads, 10 instr.]
	}
\end{lstlisting}

Based on this code structure, the formulas to estimate the number of memory accesses and total number of instructions can be easily deduced:

\begin{IEEEeqnarray}{CrClC}
\Rightarrow		&	\mathrm{\#MemAccesses}	&	=	&	(9N + 14)N + 6N	&	\Leftrightarrow	\nonumber	\\
				&							&	=	&	9N^{2} + 20N	&	\nonumber
\end{IEEEeqnarray}

\begin{IEEEeqnarray}{CrClC}
\Rightarrow		&	\mathrm{\#TotalIns}		&	=	&	(34N + 33)N + 10N	&	\Leftrightarrow	\nonumber	\\
				&							&	=	&	34N^{2} + 43N		&	\nonumber
\end{IEEEeqnarray}

\autoref{fig:memaccesses} and \autoref{fig:memaccesseserror} show the estimation calculated from these formulas, along with the approximated value returned from PAPI, and the error of the estimation. The estimation based on assembly analysis proved to be quite accurate. The estimation is very precise, with the error being near 0\% for the bigger cases.

\begin{figure}[!htp]
	\begin{minipage}[t]{0.5\linewidth}
		\includegraphics[width=\textwidth]{images/chart01_mem_accesses.png}
		\caption{Memory Accesses \label{fig:memaccesses}}
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}[t]{0.5\linewidth}
		\includegraphics[width=\textwidth]{images/chart02_mem_accesses_error.png}
		\caption{Estimation Error \label{fig:memaccesseserror}}
	\end{minipage}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 3.2: Miss rates
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Cache usage}

Usage of both levels of cache was estimated with specific counters. PAPI\_L1\_DCA and PAPI\_L2\_DCA provided the number of data accesses to the caches, while PAPI\_L1\_DCM and PAPI\_L2\_DCM provided number of misses. It should be noted that the counters for L2 cache are not native, and there were some problems using them, like negative values on some first tests. This might indicate that those counters are not fully reliable.

he graphs in this section give information about cache misses and memory accesses. \autoref{fig:cachel1} and \autoref{fig:cachel2} show the total number of accesses and misses for each cache level.

\begin{figure}[!htp]
	\begin{minipage}[t]{0.5\linewidth}
		\includegraphics[width=\textwidth]{images/chart03\_cache\_l1.png}
		\caption{Cache L1 \label{fig:cachel1}}
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}[t]{0.5\linewidth}
		\includegraphics[width=\textwidth]{images/chart04\_cache\_l2.png}
		\caption{Cache L2 \label{fig:cachel2}}
	\end{minipage}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{9}
\bibitem{roofline}
	\texttt{\small
	Roofline: An insightful Visual Performance Model for Floating-Point Programs and Multicore Architectures}	\\
	\emph{Samuel Webb Williams, Andre Waterman, David A. Patterson}	\\
	28th November 2011

\bibitem{ark}
	\texttt{\small
	http://ark.intel.com/products/35568/Intel-Core2-Duo-Processor-P8600}	\\
	\emph{Intel{\textregistered} Core 2 Duo{\texttrademark} P8600}	\\
	{\copyright}Intel Corporation	\\
	28th November 2011

\bibitem{intelmanual}
	\texttt{\small
	Intel{\textregistered} 64 and IA-32 Architectures Software Developer Manuals}	\\
	{\copyright}Intel Corporation	\\
	29th November 2011

\bibitem{sqrt}
	Best Square Root Method - Algorithm - Function (Precision VS Speed)	\\
	http://www.codeproject.com/KB/cpp/Sqrt\_Prec\_VS\_Speed.aspx	\\
	\emph{Mahmoud Hesham El-Magdoub} \\
	15th September 2010

\end{thebibliography}

\end{document}
